{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# Ref \n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# https://sites.google.com/view/zsgititit/home/ji-qi-xue-xi/%E4%BD%BF%E7%94%A8python%E7%B6%93%E7%94%B1chatgpt-api%E9%80%B2%E8%A1%8C%E5%95%8F%E7%AD%94\n",
    "\n",
    "# https://platform.openai.com/api-keys\n",
    "\n",
    "# https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/4/summarizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use openai==0.28 for old API\n",
    "\n",
    "\n",
    "#!pip uninstall openai\n",
    "#!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Basic API Test\n",
    "#----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-8hgMe6Ewpqi4Zuu1ruuf7zno8piV1\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1705421644,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 5,\n",
      "    \"completion_tokens\": 14,\n",
      "    \"total_tokens\": 19\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Call the ChatGPT API\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "prompt = \"Tell me a joke.\"\n",
    "\n",
    "# Call the ChatGPT API using the new ChatCompletion interface\n",
    "response = openai.Completion.create(\n",
    "    engine=\"gpt-3.5-turbo-instruct\",  # Use the appropriate engine for ChatGPT\n",
    "    prompt=prompt,\n",
    "    max_tokens=100  # You can adjust this parameter as needed\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "#print(response['choices'][0]['message']['content'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Generate a Simple Post\n",
    "#----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-8hgOXdj5MfrS4hEB6JfIbWDHuG3Ph\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1705421761,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \" about the benefits of regular exercise\\n\\nRegular exercise is essential for maintaining a healthy and balanced lifestyle. Not only does it help in keeping your body fit and toned, but it also has numerous benefits for your overall health and well-being. In this article, we will discuss some of the top benefits of regular exercise and why it should be an integral part of your daily routine.\\n\\n1. Improved Physical Health:\\n\\nThe most obvious benefit of regular exercise is its positive impact on physical health. Engaging in physical\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 5,\n",
      "    \"completion_tokens\": 100,\n",
      "    \"total_tokens\": 105\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"please generate a SEO post\"\n",
    "\n",
    "# Call the ChatGPT API using the new ChatCompletion interface\n",
    "response = openai.Completion.create(\n",
    "    engine=\"gpt-3.5-turbo-instruct\",  # Use the appropriate engine for ChatGPT\n",
    "    prompt=prompt,\n",
    "    max_tokens=100  # You can adjust this parameter as needed\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about the benefits of regular exercise\n",
      "\n",
      "Regular exercise is essential for maintaining a healthy and balanced lifestyle. Not only does it help in keeping your body fit and toned, but it also has numerous benefits for your overall health and well-being. In this article, we will discuss some of the top benefits of regular exercise and why it should be an integral part of your daily routine.\n",
      "\n",
      "1. Improved Physical Health:\n",
      "\n",
      "The most obvious benefit of regular exercise is its positive impact on physical health. Engaging in physical\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Generate a Simple Post\n",
    "#----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-8hgTb567QrsycccGBGAb66c42CxbU\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1705422075,\n",
      "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\nTaiwan President Election: Impact on Semi-Conductor Industry and Regional Balance\\n\\nThe recent presidential election in Taiwan has garnered global attention, with major implications for the country's semi-conductor industry and international relations. President Tsai Ing-wen of the Democratic Progressive Party (DPP) secured a landslide victory against her opponent Han Kuo-yu of the Kuomintang (KMT) party, in a historic win for Taiwan's pro-independence camp. The implications of this election go beyond\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 46,\n",
      "    \"completion_tokens\": 100,\n",
      "    \"total_tokens\": 146\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Please generate a SEO post with key words :\n",
    "  1) Taiwan president election\n",
    "  2) Semi-conductor\n",
    "  3) international relation\n",
    "  4) regional balance\n",
    "  \n",
    "  Must have 400 words\n",
    "\"\"\"\n",
    "\n",
    "# Call the ChatGPT API using the new ChatCompletion interface\n",
    "response = openai.Completion.create(\n",
    "    engine=\"gpt-3.5-turbo-instruct\",  # Use the appropriate engine for ChatGPT\n",
    "    prompt=prompt,\n",
    "    max_tokens=100  # You can adjust this parameter as needed\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Taiwan President Election: Impact on Semi-Conductor Industry and Regional Balance\n",
      "\n",
      "The recent presidential election in Taiwan has garnered global attention, with major implications for the country's semi-conductor industry and international relations. President Tsai Ing-wen of the Democratic Progressive Party (DPP) secured a landslide victory against her opponent Han Kuo-yu of the Kuomintang (KMT) party, in a historic win for Taiwan's pro-independence camp. The implications of this election go beyond\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Mix some artitcles\n",
    "#----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Please mix below 3 posts\n",
    "\n",
    "\n",
    "1) Kubernetes is an open-source container orchestration system for automating software deployment, scaling, and management. Originally designed by Google, the project is now maintained by the Cloud Native Computing Foundation. \n",
    "2) MLOps or ML Ops is a paradigm that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of \"machine learning\" and the continuous development practice of DevOps in the software field.\n",
    "3) Amazon SageMaker is a cloud based machine-learning platform that allows the creation, training, and deployment by developers of machine-learning models on the cloud. It can be used to deploy ML models on embedded systems and edge-devices. \n",
    "\n",
    "\n",
    "  Must offer insightful ideas\n",
    "  Must offer new perspective\n",
    "  \n",
    "  pleae offer result in 3000 words\n",
    "\"\"\"\n",
    "\n",
    "# Call the ChatGPT API using the new ChatCompletion interface\n",
    "response = openai.Completion.create(\n",
    "    engine=\"gpt-3.5-turbo-instruct\",  # Use the appropriate engine for ChatGPT\n",
    "    prompt=prompt,\n",
    "    max_tokens=300  # You can adjust this parameter as needed\n",
    ")\n",
    "\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------> token = 100\n",
      "lenth = 590\n",
      "\n",
      "The world of technology is constantly evolving, and with the rise of cloud computing and machine learning, new innovative tools and methodologies have emerged. In recent years, Kubernetes has become one of the most popular open-source platforms for container orchestration. Its ability to automate software deployment, scaling, and management has revolutionized the way organizations handle their applications. However, with the increasing complexity of machine learning models, a new paradigm called MLOps has emerged to address the challenges of deploying and maintaining these models in\n",
      "\n",
      "\n",
      "---------> token = 300\n",
      "lenth = 1704\n",
      "\n",
      "The world of technology is constantly evolving, with new innovations and advancements emerging everyday. In recent years, two concepts that have gained significant attention and adoption in the tech community are Kubernetes and MLOps. Both of these have revolutionized how organizations approach software development and deployment, with the ultimate goal of making their operations more efficient and effective. In this essay, we will explore the potential of these two technologies and how they can work together to offer a new perspective for organizations in their journey towards success.\n",
      "\n",
      "Kubernetes, an open-source container orchestration system, was originally designed by Google. With its powerful features such as automated deployment, scaling, and management of applications in containers, it has become a popular choice for many organizations. The project is now maintained by the Cloud Native Computing Foundation (CNCF), a non-profit organization that fosters the growth and adoption of cloud-native technologies. Through Kubernetes, developers can easily deploy and manage their applications in containers, ensuring scalability, fault tolerance, and efficient resource utilization.\n",
      "\n",
      "On the other hand, MLOps, also known as Machine Learning Operations, is a relatively new concept that has gained traction in recent years. The term is a combination of \"machine learning\" and \"operations,\" and it refers to the practice of deploying and managing machine learning models in production. With the rise in the use of machine learning in various industries, organizations have realized the need for an efficient and reliable way to deploy and manage their ML models. And that's where MLOps comes\n",
      "\n",
      "\n",
      "---------> token = 1000\n",
      "lenth = 5607\n",
      "\n",
      "Kubernetes and MLOps have been two groundbreaking developments in the world of software development and deployment. With the increasing popularity of cloud computing, these tools have become essential for businesses looking to scale and manage their operations efficiently. However, when it comes to deploying machine learning models in production, both Kubernetes and MLOps have their strengths and limitations. In this article, we will explore the benefits of using Amazon SageMaker, a cloud-based machine learning platform, for deploying models onto edge devices and how it can complement the functionalities of Kubernetes and MLOps.\n",
      "\n",
      "Kubernetes is a powerful tool that allows developers to manage and deploy their containerized applications with ease. Containerization has become a popular method for packaging and deploying applications, thanks to its simplicity and portability. However, managing large-scale containerized applications can be complex and time-consuming, requiring significant investments in infrastructure and skilled resources. This is where Kubernetes comes in, offering automated orchestration and management of containers, making it easier to scale and manage applications. With Kubernetes, businesses can achieve high levels of automation, flexibility, and availability, making it an ideal choice for deploying software applications in production.\n",
      "\n",
      "On the other hand, MLOps has emerged as a paradigm that aims to apply DevOps principles to machine learning. Machine learning models have different requirements from traditional software applications, and MLOps helps bridge the gap between data science and software development. This approach ensures that machine learning models are deployed and maintained reliably and efficiently in production, reducing the risk of model performance degradation. With MLOps, businesses can achieve faster deployment of models and improved collaboration between data science and IT teams, leading to more accurate and effective models.\n",
      "\n",
      "Now, let's take a closer look at Amazon SageMaker and how it offers a unique solution for deploying machine learning models on edge devices. SageMaker is a cloud-based machine learning platform that offers a comprehensive set of tools for developers to build, train, and deploy their models on the cloud. It simplifies the process of building and deploying models, making it accessible to developers of all levels of expertise. With SageMaker, developers can choose from a variety of machine learning frameworks, including TensorFlow, PyTorch, and MXNet, to develop their models. Additionally, SageMaker integrates with other services on the cloud, such as Amazon S3 for data storage and Amazon Rekognition for image and video analysis, making it a one-stop-shop for developing and deploying machine learning models.\n",
      "\n",
      "One of the key advantages of using SageMaker is its ability to deploy models on edge devices. Edge computing has gained immense popularity over the years, with the rise in the Internet of Things (IoT) devices. These devices, often located in remote areas with limited connectivity, require models to be deployed locally, as sending data back and forth to the cloud can be costly and inefficient. This is where SageMaker's edge device support comes in, offering developers the ability to deploy their models on a variety of devices, including Amazon EC2 instances, Raspberry Pi, and other embedded devices. With SageMaker, developers can achieve low latency and reduced costs by deploying models closer to their data sources, improving data security and privacy.\n",
      "\n",
      "Moreover, SageMaker offers a range of features that make it an ideal choice for deploying machine learning models on edge devices. It offers built-in support for optimized deep learning libraries like Apache MXNet, TensorFlow, and PyTorch, making it easier to develop and deploy models with high performance on edge devices. Additionally, it provides a pre-installed Amazon SageMaker Neo runtime that optimizes the model for the targeted device, resulting in faster and more efficient execution. SageMaker also offers built-in support for Automatic Model Tuning, which helps to find the best model hyperparameters for a specific use case, resulting in improved model performance and reduced time and resources spent on manual tuning.\n",
      "\n",
      "Furthermore, SageMaker offers a container-based deployment option that allows models built in a Docker container to be easily deployed on edge devices using Kubernetes. This integration provides a smooth and seamless experience for developers, allowing them to use the same containerized models on both cloud and edge environments. By utilizing Kubernetes for deploying models on edge devices, developers can achieve higher levels of automation and scalability, making it easier to manage and update models remotely.\n",
      "\n",
      "In conclusion, Amazon SageMaker offers a unique solution for deploying machine learning models on edge devices, complementing the functionalities of Kubernetes and MLOps. With its scalability, automation, and support for a variety of machine learning frameworks and edge devices, SageMaker makes it easier for developers to deploy and manage models in production. By combining the capabilities of SageMaker with Kubernetes and MLOps, businesses can achieve improved agility, efficiency, and reliability in their machine learning deployments, leading to significant business benefits. As cloud computing and edge computing continue to evolve, SageMaker is poised to become a crucial tool for businesses looking to leverage the power of machine learning in their operations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in [100, 300, 1000]:\n",
    "    response = openai.Completion.create(\n",
    "    engine=\"gpt-3.5-turbo-instruct\",  # Use the appropriate engine for ChatGPT\n",
    "    prompt=prompt,\n",
    "    max_tokens=token  # You can adjust this parameter as needed\n",
    "    )\n",
    "    print()\n",
    "    print (\"---------> token = \" + str(token))\n",
    "    print (\"lenth = \" + str(len(response[\"choices\"][0][\"text\"])))\n",
    "    print(response[\"choices\"][0][\"text\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
